{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "00_full_openvino_pipeline_pic.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajankowski/openvino/blob/master/00_full_openvino_pipeline_pic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCFkAPunduI0"
      },
      "source": [
        "<img src='https://cdn-images-1.medium.com/fit/t/1600/480/1*_F330rP3SPZ-xhQKYQ1qhQ.png' height=100>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72n-9Ny06Zt4"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=1w5dkGo71eFE_odBmUnvpC_BZ87u2rl2P'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTGB0GO86_Sg"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=1SZGkdOqR0MCuquznMnkdMdDLLxgpIarX'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz033jis7xib"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=123kbrrHJ4dHtMdpwBfkwSNDKZILtXNot'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46TS5uMh77HB"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=12tlvIVIrfrq_QyVpBUn0nIZxuPIg3qiZ'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze_VpIVSRSCK"
      },
      "source": [
        "# Installing OpenVino and libraries import\n",
        "<img src='https://miro.medium.com/max/3000/1*vdjibkLyilWAq-7CONW8Zg.png' height=100>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_xFHDYvSohE"
      },
      "source": [
        "# Install OpenVino\n",
        "\n",
        "!wget https://apt.repos.intel.com/openvino/2021/GPG-PUB-KEY-INTEL-OPENVINO-2021\n",
        "!apt-key add GPG-PUB-KEY-INTEL-OPENVINO-2021\n",
        "!touch /etc/apt/sources.list.d/intel-openvino-2021.list\n",
        "!echo \"deb https://apt.repos.intel.com/openvino/2021 all main\" >> /etc/apt/sources.list.d/intel-openvino-2021.list\n",
        "!pip install test-generator==0.1.1\n",
        "!apt update\n",
        "!apt install intel-openvino-dev-ubuntu18-2021.3\n",
        "\n",
        "!pip install openvino"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9WDLrdkIxZE"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-nPqdiFRJVh"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWGiTRtvxwJB"
      },
      "source": [
        "# MNIST data\n",
        "<img src='https://miro.medium.com/max/584/1*2lSjt9YKJn9sxK7DSeGDyw.jpeg' height=200>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcUeF3mFRJp-"
      },
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = datasets.mnist.load_data()\n",
        "data = train_data.astype(np.float32)\n",
        "data = data /255\n",
        "data = data.reshape(-1, 784)\n",
        "\n",
        "classes = 10\n",
        "labels = tf.keras.utils.to_categorical(train_labels, classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJbu92dXRTH5"
      },
      "source": [
        "# model\n",
        "<img src='https://cdn-images-1.medium.com/max/550/1*pO5X2c28F1ysJhwnmPsy3Q.gif' height=250>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLdiJpKdRJs0"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(100, activation='relu', input_shape=(784, )))\n",
        "model.add(layers.Dense(100, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(data, labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbUcWJzSRsjY"
      },
      "source": [
        "# saving the model\n",
        "converting a model saved in keras (.h5) to saved_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJpAHG_RRJya"
      },
      "source": [
        "model.save('simple_model.h5') # keras API for saving model\n",
        "\n",
        "model_ov = tf.keras.models.load_model('simple_model.h5')\n",
        "tf.saved_model.save(model_ov,'saved_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUJae65ZRy4y"
      },
      "source": [
        "<img src='https://cdn-images-1.medium.com/fit/t/1600/480/1*_F330rP3SPZ-xhQKYQ1qhQ.png' height=100>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fadiXUZh8I0J"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=1I3uejNH_hN5HmtDVYT2r0lnqJbPh0jmY'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwHLsf_ZRJ01"
      },
      "source": [
        "mo_tf_path = '/opt/intel/openvino_2021/deployment_tools/model_optimizer/mo_tf.py'\n",
        "\n",
        "model_dir = '/content/saved_model'\n",
        "output_dir = '/content/'\n",
        "input_shape = [1, 784]\n",
        "input_shape_str = str(input_shape).replace(' ', '')\n",
        "\n",
        "#Running Commands to run OPENVINO's Model Optimiser Converter 'mo_tf.py'\n",
        "!python {mo_tf_path} --saved_model_dir {model_dir} --output_dir {output_dir} --input_shape {input_shape_str} --data_type FP16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26caPzusxdg_"
      },
      "source": [
        "! ls \n",
        "# !cat /content/saved_model.xml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV6fp8OKvuJT"
      },
      "source": [
        "# sample digit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTmIuR-Tt1iX"
      },
      "source": [
        "i = 58\n",
        "\n",
        "test_digit = test_data[i]\n",
        "test_label = test_labels[i]\n",
        "\n",
        "img = Image.fromarray(test_digit)\n",
        "img.save('test_image.png')\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title(f'label: {test_label}')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqVxjDejZE8-"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=1M1wna8H8WyciiiOErvii3VmFE0Xk4t0O'>\n",
        "\n",
        "**Due to running it in colab environment we have to run inference through bash script,  \n",
        " in a regular environment you would call python code directly.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-bSFmN7IN7P"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from openvino.inference_engine import IECore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5lI9_ubIONV"
      },
      "source": [
        "# image preprocessing\n",
        "def load_image(input_path):    \n",
        "    capture = cv2.VideoCapture(input_path)       \n",
        "    ret, image = capture.read()\n",
        "    del capture    \n",
        "    return image \n",
        "\n",
        "def prepare_image(image):\n",
        "    resized = cv2.resize(image, (28, 28)) # resize image\n",
        "    try:\n",
        "        gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY) # change image to grayscale\n",
        "    except:\n",
        "        gray = resized\n",
        "    reshaped = gray.reshape((1,) + ((gray.shape[0]*gray.shape[1]),)) # reshape from 28X28 to 1X784 (input_shape of our model)\n",
        "    flipped = (255 - reshaped) /255 # flip color values and rescale from 0-255 to 0-1\n",
        "    return reshaped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF5Qt-imIOau"
      },
      "source": [
        "# optimized model location\n",
        "model_xml = '/content/saved_model.xml'\n",
        "model_bin = '/content/saved_model.bin'\n",
        "\n",
        "image_path = '/content/test_image.png'\n",
        "\n",
        "# inference engine\n",
        "ie = IECore()\n",
        "\n",
        "net = ie.read_network(model=model_xml, weights=model_bin)\n",
        "model_openvino = ie.load_network(network=net, num_requests=1, device_name='CPU')\n",
        "\n",
        "# inputs and outputs\n",
        "input_blob= next(iter(net.input_info)) \n",
        "output_blob = next(iter(net.outputs))\n",
        "\n",
        "image = load_image(image_path)\n",
        "prepared_image = prepare_image(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPX-8xiJIOrF"
      },
      "source": [
        "# tf inference\n",
        "model_tf = tf.keras.models.load_model('/content/simple_model.h5')\n",
        "prediction_tf = model_tf.predict(prepared_image)\n",
        "\n",
        "# openvino inference\n",
        "prediction = model_openvino.infer(inputs={input_blob: prepared_image})\n",
        "\n",
        "print(40*'-')\n",
        "print(f'OpenVino prediction: {prediction}')\n",
        "print(40*'-')\n",
        "print(f'TensorFlow prediction: {prediction_tf}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24hH9K86Ko_f"
      },
      "source": [
        "%%time\n",
        "prediction_tf = model.predict(prepared_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHV-1n41KsZN"
      },
      "source": [
        "%%time\n",
        "prediction = model_openvino.infer(inputs={input_blob: prepared_image})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsB8JGjvKu5F"
      },
      "source": [
        "%%timeit -r 3 -n 10\n",
        "prediction_tf = model.predict(prepared_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvh05kSaKyaN"
      },
      "source": [
        "%%timeit -r 3 -n 10\n",
        "prediction = model_openvino.infer(inputs={input_blob: prepared_image})"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}